{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfB1Otjb3VagexCIyt4Hux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim97/pytorch-resnet-mnist/blob/master/MNISTResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4kKlVC_gUac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "import inspect\n",
        "import time\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "import urllib\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import BatchSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as5am2P6cF3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_workers = 0\n",
        "batch_size = 20\n",
        "basepath = '.'\n",
        "\n",
        "def set_header_for(url, filename):\n",
        "    opener = urllib.request.URLopener()\n",
        "    opener.addheader('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36')\n",
        "    opener.retrieve(\n",
        "    url, f'{basepath}/{filename}')\n",
        "\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyYP1Oshued",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistResNet(ResNet):\n",
        "  def __init__(self):\n",
        "    super(MnistResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "    self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "  def forward(self, x):\n",
        "    return torch.softmax(super(MnistResNet, self).forward(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjriG1vnd8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "def get_same_indices(target, labels):\n",
        "  label_indices = []\n",
        "  for i in range (len(target)):\n",
        "    for j in range (len(labels)):\n",
        "      if target[i] == labels[j]:\n",
        "        label_indices.append(i)\n",
        "  return label_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz1J1M5wiK8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loaders(train_batch_size, val_batch_size):\n",
        "  mnist = MNIST(download=True, train=True, root=\".\").train_data.float()\n",
        "    \n",
        "  data_transform = Compose([Resize((224, 224)),ToTensor(), Normalize((mnist.mean()/255,), (mnist.std()/255,))])\n",
        "\n",
        "  train_dataset = MNIST(download=True, root=\".\", transform=data_transform, train=True)\n",
        "  train_indices = get_same_indices(train_dataset.targets, train_label_classes)\n",
        "  train_loader = DataLoader(dataset = train_dataset, batch_size=train_batch_size, shuffle=False, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_indices))\n",
        "\n",
        "  val_dataset = MNIST(download=False, root=\".\", transform=data_transform, train=False)\n",
        "  # val_indices = get_same_indices(val_dataset.targets, test_label_classes)\n",
        "  val_classes = [100, 100, 100, 100, 100, 100, 100, 100, 100, 13]\n",
        "  weights = 1 / torch.Tensor(val_classes)\n",
        "  val_loader = DataLoader(dataset = val_dataset, batch_size=val_batch_size, shuffle=False, sampler=torch.utils.data.sampler.WeightedRandomSampler(weights, val_batch_size))\n",
        "  # val_loader = DataLoader(dataset = val_dataset, batch_size=train_batch_size, shuffle=False, sampler=torch.utils.data.sampler.SubsetRandomSampler(val_indices))\n",
        "\n",
        "  return train_loader, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioMn7cELiRFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "  if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "    return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "  else:\n",
        "    return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "  for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "    print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtBAg820iazl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_ts = time.time()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 50\n",
        "\n",
        "model = MnistResNet().to(device)\n",
        "train_loader, val_loader = get_data_loaders(256, 256)\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "#training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "    model.train()\n",
        "    \n",
        "    for i, data in progress:\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = loss_function(outputs, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss\n",
        "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}\")\n",
        "    losses.append(total_loss/batches)\n",
        "    print(losses)\n",
        "    print(f\"Training time: {time.time()-start_ts}s\")\n",
        "    model_filename = 'model.pth'\n",
        "    torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "val_losses = 0\n",
        "precision, recall, f1, accuracy = [], [], [], []\n",
        "\n",
        "confusion_actuals = []\n",
        "probabilities = []\n",
        "predictions = []\n",
        "roc_actuals = []\n",
        "\n",
        "which_class = 9\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\"))\n",
        "# validation loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_np = y.cpu().numpy()\n",
        "\n",
        "        x_val_zeros = X[y_np == 0]\n",
        "        x_val_ones = X[y_np== 1]\n",
        "        x_val_twos = X[y_np == 2]\n",
        "        x_val_threes = X[y_np == 3]\n",
        "        x_val_fours = X[y_np == 4]\n",
        "        x_val_fives = X[y_np == 5]\n",
        "        x_val_sixes = X[y_np == 6]\n",
        "        x_val_sevens = X[y_np == 7]\n",
        "        x_val_eights = X[y_np == 8]\n",
        "        x_val_nines = X[y_np == 9]\n",
        "\n",
        "        print(len(x_val_zeros), len(x_val_ones), len(x_val_twos), len(x_val_threes), len(x_val_fours), len(x_val_fives), len(x_val_sixes), len(x_val_sevens), len(x_val_eights), len(x_val_nines))\n",
        "        outputs = model(X)\n",
        "        prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "        confusion_actuals.extend(y.view_as(prediction))\n",
        "        roc_actuals.extend(y.view_as(prediction) == which_class)\n",
        "        probabilities.extend(np.exp(outputs.cpu()[:, which_class]))  \n",
        "        predictions.extend(prediction)\n",
        "\n",
        "        val_losses += loss_function(outputs, y)\n",
        "\n",
        "        predicted_classes = torch.max(outputs, 1)[1]\n",
        "        \n",
        "        for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "                                (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "            acc.append(\n",
        "                calculate_metric(metric, y.cpu(), predicted_classes.cpu())\n",
        "            )\n",
        "\n",
        "confusion_actuals = [i.item() for i in confusion_actuals]\n",
        "predictions = [i.item() for i in predictions]\n",
        "roc_actuals = [i.item() for i in roc_actuals]\n",
        "class_probabilities = [i.item() for i in probabilities]\n",
        "\n",
        "# confusion_mtrx = confusion_matrix(confusion_actuals, predictions)\n",
        "\n",
        "# FP = confusion_mtrx.sum(axis=0) - np.diag(confusion_mtrx)  \n",
        "# FN = confusion_mtrx.sum(axis=1) - np.diag(confusion_mtrx)\n",
        "# TP = np.diag(confusion_mtrx)\n",
        "# TN = confusion_mtrx.sum() - (FP + FN + TP)\n",
        "\n",
        "# # Sensitivity, hit rate, recall, or true positive rate\n",
        "# TPR = TP/(TP+FN)\n",
        "# # Fall out or false positive rate\n",
        "# FPR = FP/(FP+TN)\n",
        "\n",
        "# print(confusion_mtrx)\n",
        "# print(\"FP\", FP)\n",
        "# print(\"FN\", FN)\n",
        "# print(\"TP\", TP)\n",
        "# print(\"TN\", TN)\n",
        "\n",
        "# print(\"TPR\", TPR)\n",
        "# print(\"FPR\", FPR)\n",
        "\n",
        "# plt.plot(FPR, TPR)\n",
        "# plt.show()\n",
        "# auc = np.trapz(TPR,FPR)\n",
        "# print('auc', auc)\n",
        "fpr, tpr, _ = roc_curve(roc_actuals, class_probabilities)\n",
        "# print(\"actuals\", roc_actuals)\n",
        "# print(\"class_probabilities\", class_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(\"auroc:\", roc_auc)\n",
        "# plt.figure()\n",
        "# lw = 2 \n",
        "# plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "# plt.plot([0, 1], [0, 1], color = 'navy', lw=lw, linestyle='--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('ROC for digit=%d class' % which_class)\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()    \n",
        "print_scores(precision, recall, f1, accuracy, val_batches)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LcYEyEgYLc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelWithTemperature(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(ModelWithTemperature, self).__init__()\n",
        "        self.model = model\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, input):\n",
        "        logits = self.model(input)\n",
        "        return self.temperature_scale(logits)\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        \"\"\"\n",
        "        Perform temperature scaling on logits\n",
        "        \"\"\"\n",
        "        # Expand temperature to match the size of logits\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature\n",
        "\n",
        "    def set_temperature(self, valid_loader):\n",
        "        self.cuda()\n",
        "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
        "        ece_criterion = _ECELoss().cuda()\n",
        "        anomaly_criterion = _AnomalyDetection().cuda()\n",
        "\n",
        "        # First: collect all the logits and labels for the validation set\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "        with torch.no_grad():\n",
        "            for input, label in valid_loader:\n",
        "                input = input.cuda()\n",
        "                logits = self.model(input)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(label)\n",
        "            logits = torch.cat(logits_list).cuda()\n",
        "            labels = torch.cat(labels_list).cuda()\n",
        "\n",
        "        # Calculate NLL and ECE before temperature scaling\n",
        "        # before_temperature_nll = nll_criterion(logits, labels).item()\n",
        "        # before_temperature_ece = ece_criterion(logits, labels).item()\n",
        "        # print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
        "\n",
        "        # Next: optimize the temperature w.r.t. NLL\n",
        "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
        "\n",
        "        def eval():\n",
        "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optimizer.step(eval)\n",
        "\n",
        "        # Calculate NLL and ECE after temperature scaling\n",
        "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_anomaly = anomaly_criterion(self.temperature_scale(logits), labels)\n",
        "        print('Optimal temperature: %.3f' % self.temperature.item())\n",
        "        print('After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece))\n",
        "        print('Anomaly Count: %d' %after_temperature_anomaly)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpY41R6ffj5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _ECELoss(nn.Module):\n",
        "    def __init__(self, n_bins=15):\n",
        "        \"\"\"\n",
        "        n_bins (int): number of confidence interval bins\n",
        "        \"\"\"\n",
        "        super(_ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "      with torch.no_grad():\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "    \n",
        "      ece = torch.zeros(1, device=logits.device)\n",
        "      for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "          # Calculated |confidence - accuracy| in each bin\n",
        "          in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "          prop_in_bin = in_bin.float().mean()\n",
        "          if prop_in_bin.item() > 0:\n",
        "              accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "              avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "              ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "      return ece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjn-A0MWjmoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _AnomalyDetection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(_AnomalyDetection, self).__init__()\n",
        "  def forward(self, logits, labels):\n",
        "    with torch.no_grad():\n",
        "      softmaxes = F.softmax(logits, dim=1)\n",
        "      confidences, predictions = torch.max(softmaxes, 1)\n",
        "      accuracies = predictions.eq(labels)\n",
        "\n",
        "    predictions_list = predictions.cpu().numpy()\n",
        "    confidences_list = confidences.cpu().numpy()\n",
        "    actuals_list = labels.cpu().numpy()\n",
        "\n",
        "    all_triples = []\n",
        "    anomaly_triples = []\n",
        "    modified_anomaly_triples = []\n",
        "\n",
        "    anomaly_count = 0\n",
        "    for i in range(len(actuals_list)):\n",
        "      all_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "      if (confidences_list[i] < 0.5):\n",
        "        anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        if (actuals_list[i] == 9):\n",
        "          predictions_list[i] = 9\n",
        "          modified_anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        anomaly_count += 1\n",
        "    print(\"all triples : \", all_triples)\n",
        "    # print(\"length of all triples: \", len(all_triples))\n",
        "    print(\"anomaly triples: \", anomaly_triples)\n",
        "    # print(\"length of anomaly triples: \", len(anomaly_triples))\n",
        "    print(\"modified anomaly triples:\", modified_anomaly_triples)\n",
        "    # print(len(anomaly_triples))\n",
        "    # print(len(modified_anomaly_triples))\n",
        "\n",
        "    conf_matrix = confusion_matrix(actuals_list, predictions_list)\n",
        "    precision = precision_score(actuals_list, predictions_list, average='macro')\n",
        "    recall = recall_score(actuals_list, predictions_list, average='macro')\n",
        "    f1 = f1_score(actuals_list, predictions_list, average='macro')\n",
        "    acc = accuracy_score(actuals_list, predictions_list)\n",
        "    print(conf_matrix) \n",
        "    print(\"Precision: %d\", precision)\n",
        "    print(\"Recall: %d\", recall)\n",
        "    print(\"F1 Score: %d\", f1)\n",
        "    print(\"Accuracy:\", acc)\n",
        "    \n",
        "\n",
        "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
        "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
        "    TP = np.diag(conf_matrix)\n",
        "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
        "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    # # Sensitivity, hit rate, recall, or true positive rate\n",
        "    # TPR = TP/(TP+FN)\n",
        "    # # Specificity or true negative rate\n",
        "    # TNR = TN/(TN+FP) \n",
        "    # # Precision or positive predictive value\n",
        "    # PPV = TP/(TP+FP)\n",
        "    # # Negative predictive value\n",
        "    # NPV = TN/(TN+FN)\n",
        "    # # Fall out or false positive rate\n",
        "    # FPR = FP/(FP+TN)\n",
        "    # # False negative rate\n",
        "    # FNR = FN/(TP+FN)\n",
        "    # # False discovery rate\n",
        "    # FDR = FP/(TP+FP)\n",
        "\n",
        "    # # Overall accuracy\n",
        "    # ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    return anomaly_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChW2cvo8fmKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_model = ModelWithTemperature(model)\n",
        "scaled_model.set_temperature(val_loader)\n",
        "\n",
        "\n",
        "anomaly_class = 9 \n",
        "actuals = []\n",
        "class_probabilities = []\n",
        "# # for i in range(len(actuals_list)):\n",
        "# #   if (actuals_list[i] == anomaly_class):\n",
        "# #     actuals.append(True)\n",
        "# #   else:\n",
        "# #     actuals.append(False)\n",
        "\n",
        "scaled_model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        print(y.cpu().numpy())\n",
        "        outputs = scaled_model(X)\n",
        "        prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "        actuals.extend(y.view_as(prediction) == anomaly_class)\n",
        "        class_probabilities.extend(np.exp(outputs.cpu()[:, anomaly_class])) \n",
        "      \n",
        "print(class_probabilities)\n",
        "# print(\"prediction\", prediction)\n",
        "# print(\"prediction len\", len(prediction))\n",
        "# print(\"actual len\", len(actuals))\n",
        "\n",
        "actuals = [i.item() for i in actuals]\n",
        "probabilities = [i.item() for i in class_probabilities]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(actuals, probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "plt.figure()\n",
        "lw = 2 \n",
        "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color = 'navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for digit=%d class' % which_class)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "model_filename = 'model_with_temperature.pth'\n",
        "torch.save(scaled_model.state_dict(), model_filename)\n",
        "print('Temperature scaled model saved to %s', model_filename)\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wPwAyxghVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
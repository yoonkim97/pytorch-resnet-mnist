{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCBOnCFXZat3olky6MY8d5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim97/pytorch-resnet-mnist/blob/master/MNISTResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4kKlVC_gUac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_curve, auc\n",
        "import inspect\n",
        "import time\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "import urllib\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as5am2P6cF3P",
        "colab_type": "code",
        "outputId": "d07ff83e-9831-4471-c508-f20c3fc73dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "\n",
        "num_workers = 0\n",
        "batch_size = 20\n",
        "basepath = '.'\n",
        "\n",
        "def set_header_for(url, filename):\n",
        "    opener = urllib.request.URLopener()\n",
        "    opener.addheader('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36')\n",
        "    opener.retrieve(\n",
        "    url, f'{basepath}/{filename}')\n",
        "\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyYP1Oshued",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistResNet(ResNet):\n",
        "  def __init__(self):\n",
        "    super(MnistResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "    self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "  def forward(self, x):\n",
        "    return torch.softmax(super(MnistResNet, self).forward(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjriG1vnd8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "def get_same_indices(target, labels):\n",
        "  label_indices = []\n",
        "  for i in range (len(target)):\n",
        "    for j in range (len(labels)):\n",
        "      if target[i] == labels[j]:\n",
        "        label_indices.append(i)\n",
        "  return label_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz1J1M5wiK8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loaders(train_batch_size, val_batch_size):\n",
        "  mnist = MNIST(download=True, train=True, root=\".\").train_data.float()\n",
        "    \n",
        "  data_transform = Compose([Resize((224, 224)),ToTensor(), Normalize((mnist.mean()/255,), (mnist.std()/255,))])\n",
        "\n",
        "  train_dataset = MNIST(download=True, root=\".\", transform=data_transform, train=True)\n",
        "  train_indices = get_same_indices(train_dataset.targets, train_label_classes)\n",
        "  train_loader = DataLoader(dataset = train_dataset, batch_size=train_batch_size, shuffle=False, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_indices))\n",
        "\n",
        "  val_dataset = MNIST(download=False, root=\".\", transform=data_transform, train=False)\n",
        "  val_indices = get_same_indices(val_dataset.targets, test_label_classes)\n",
        "  val_loader = DataLoader(dataset = val_dataset, batch_size=val_batch_size, shuffle=False, sampler=torch.utils.data.sampler.SubsetRandomSampler(val_indices))\n",
        "  return train_loader, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioMn7cELiRFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "  if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "    return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "  else:\n",
        "    return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "  for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "    print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtBAg820iazl",
        "colab_type": "code",
        "outputId": "208881e5-bf3a-469a-c0e1-c8c6b027b798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_ts = time.time()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 5\n",
        "\n",
        "model = MnistResNet().to(device)\n",
        "train_loader, val_loader = get_data_loaders(256, 256)\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "# training loop + eval loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "    model.train()\n",
        "    \n",
        "    for i, data in progress:\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = loss_function(outputs, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss\n",
        "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    val_losses = 0\n",
        "    precision, recall, f1, accuracy = [], [], [], []\n",
        "    \n",
        "    confusion_actuals = []\n",
        "    probabilities = []\n",
        "    predictions = []\n",
        "    roc_actuals = []\n",
        "\n",
        "    which_class = 9\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            X, y = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(X)\n",
        "            prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "            confusion_actuals.extend(y.view_as(prediction))\n",
        "            roc_actuals.extend(y.view_as(prediction) == which_class)\n",
        "            probabilities.extend(np.exp(outputs.cpu()[:, which_class]))  \n",
        "            predictions.extend(prediction)\n",
        "\n",
        "            val_losses += loss_function(outputs, y)\n",
        "\n",
        "            predicted_classes = torch.max(outputs, 1)[1]\n",
        "            \n",
        "            for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "                                   (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "                acc.append(\n",
        "                    calculate_metric(metric, y.cpu(), predicted_classes.cpu())\n",
        "                )\n",
        "    confusion_actuals = [i.item() for i in confusion_actuals]\n",
        "    predictions = [i.item() for i in predictions]\n",
        "    roc_actuals = [i.item() for i in roc_actuals]\n",
        "    class_probabilities = [i.item() for i in probabilities]\n",
        "\n",
        "    print(roc_actuals)\n",
        "    print(class_probabilities)\n",
        "\n",
        "    # fpr, tpr, _ = roc_curve(roc_actuals, class_probabilities)\n",
        "    # roc_auc = auc(fpr, tpr)\n",
        "    # plt.figure()\n",
        "    # lw = 2 \n",
        "    # plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    # plt.plot([0, 1], [0, 1], color = 'navy', lw=lw, linestyle='--')\n",
        "    # plt.xlim([0.0, 1.0])\n",
        "    # plt.ylim([0.0, 1.05])\n",
        "    # plt.xlabel('False Positive Rate')\n",
        "    # plt.ylabel('True Positive Rate')\n",
        "    # plt.title('ROC for digit=%d class' % which_class)\n",
        "    # plt.legend(loc=\"lower right\")\n",
        "    # plt.show()\n",
        "        \n",
        "    print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "    print(confusion_matrix(confusion_actuals, predictions))    \n",
        "    print_scores(precision, recall, f1, accuracy, val_batches)\n",
        "    losses.append(total_loss/batches)\n",
        "print(losses)\n",
        "print(f\"Training time: {time.time()-start_ts}s\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d6c1e7d3494ca88f35cf50b8e2d1c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loss: ', max=212, style=ProgressStyle(description_width='initâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LcYEyEgYLc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelWithTemperature(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(ModelWithTemperature, self).__init__()\n",
        "        self.model = model\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, input):\n",
        "        logits = self.model(input)\n",
        "        return self.temperature_scale(logits)\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        \"\"\"\n",
        "        Perform temperature scaling on logits\n",
        "        \"\"\"\n",
        "        # Expand temperature to match the size of logits\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature\n",
        "\n",
        "    def set_temperature(self, valid_loader):\n",
        "        self.cuda()\n",
        "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
        "        ece_criterion = _ECELoss().cuda()\n",
        "        anomaly_criterion = _AnomalyDetection().cuda()\n",
        "\n",
        "        # First: collect all the logits and labels for the validation set\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "        with torch.no_grad():\n",
        "            for input, label in valid_loader:\n",
        "                input = input.cuda()\n",
        "                logits = self.model(input)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(label)\n",
        "            logits = torch.cat(logits_list).cuda()\n",
        "            labels = torch.cat(labels_list).cuda()\n",
        "\n",
        "        # Calculate NLL and ECE before temperature scaling\n",
        "        # before_temperature_nll = nll_criterion(logits, labels).item()\n",
        "        # before_temperature_ece = ece_criterion(logits, labels).item()\n",
        "        # print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
        "\n",
        "        # Next: optimize the temperature w.r.t. NLL\n",
        "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
        "\n",
        "        def eval():\n",
        "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optimizer.step(eval)\n",
        "\n",
        "        # Calculate NLL and ECE after temperature scaling\n",
        "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_anomaly = anomaly_criterion(self.temperature_scale(logits), labels)\n",
        "        print('Optimal temperature: %.3f' % self.temperature.item())\n",
        "        print('After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece))\n",
        "        print('Anomaly Count: %d' %after_temperature_anomaly)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpY41R6ffj5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _ECELoss(nn.Module):\n",
        "    def __init__(self, n_bins=15):\n",
        "        \"\"\"\n",
        "        n_bins (int): number of confidence interval bins\n",
        "        \"\"\"\n",
        "        super(_ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "      with torch.no_grad():\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "    \n",
        "      ece = torch.zeros(1, device=logits.device)\n",
        "      for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "          # Calculated |confidence - accuracy| in each bin\n",
        "          in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "          prop_in_bin = in_bin.float().mean()\n",
        "          if prop_in_bin.item() > 0:\n",
        "              accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "              avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "              ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "      return ece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjn-A0MWjmoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _AnomalyDetection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(_AnomalyDetection, self).__init__()\n",
        "  def forward(self, logits, labels):\n",
        "    with torch.no_grad():\n",
        "      softmaxes = F.softmax(logits, dim=1)\n",
        "      confidences, predictions = torch.max(softmaxes, 1)\n",
        "      accuracies = predictions.eq(labels)\n",
        "\n",
        "    predictions_list = predictions.cpu().numpy()\n",
        "    confidences_list = confidences.cpu().numpy()\n",
        "    actuals_list = labels.cpu().numpy()\n",
        "\n",
        "    all_triples = []\n",
        "    anomaly_triples = []\n",
        "    modified_anomaly_triples = []\n",
        "\n",
        "    anomaly_count = 0\n",
        "    for i in range(len(actuals_list)):\n",
        "      all_triples.append((actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "      if (confidences_list[i] < 0.80):\n",
        "        anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        if (actuals_list[i] == 9):\n",
        "          predictions_list[i] = 9\n",
        "          modified_anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        anomaly_count += 1\n",
        "    print(anomaly_triples)\n",
        "    print(modified_anomaly_triples)\n",
        "    print(len(anomaly_triples))\n",
        "    print(len(modified_anomaly_triples))\n",
        "\n",
        "    conf_matrix = confusion_matrix(actuals_list, predictions_list)\n",
        "    precision = precision_score(actuals_list, predictions_list, average='macro')\n",
        "    recall = recall_score(actuals_list, predictions_list, average='macro')\n",
        "    f1 = f1_score(actuals_list, predictions_list, average='macro')\n",
        "    print(conf_matrix) \n",
        "    print(\"Precision: %d\", precision)\n",
        "    print(\"Recall: %d\", recall)\n",
        "    print(\"F1 Score: %d\", f1)\n",
        "\n",
        "    anomaly_class = 9 \n",
        "    actuals = []\n",
        "    confidences = []\n",
        "    for i in range(len(actuals_list)):\n",
        "      if (actuals_list[i] == anomaly_class):\n",
        "        actuals.append(actuals_list[i])\n",
        "        confidences.append(confidences_list[i])\n",
        "\n",
        "    print(actuals)\n",
        "    print(confidences)\n",
        "    fpr, tpr, _ = roc_curve(actuals, confidences)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(roc_auc)\n",
        "    return anomaly_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChW2cvo8fmKj",
        "colab_type": "code",
        "outputId": "60e55172-f76b-46ff-abbc-00396666fb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "scaled_model = ModelWithTemperature(model)\n",
        "scaled_model.set_temperature(val_loader)\n",
        "\n",
        "\n",
        "model_filename = 'model_with_temperature.pth'\n",
        "torch.save(scaled_model.state_dict(), model_filename)\n",
        "print('Temperature scaled model saved to %s', model_filename)\n",
        "print('Done!')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(57, 8, 8, 0.6025449), (68, 9, 7, 0.36073866), (88, 9, 4, 0.54358953), (125, 9, 7, 0.46659192), (149, 9, 4, 0.5654679), (176, 9, 7, 0.65573764), (236, 9, 4, 0.7288132), (242, 8, 5, 0.50411546), (243, 8, 6, 0.72702235), (319, 9, 7, 0.70804584), (320, 9, 5, 0.6563065), (322, 9, 4, 0.56559986), (327, 9, 4, 0.62139213), (347, 9, 7, 0.6404826), (378, 9, 4, 0.44418088), (429, 9, 4, 0.39046547), (444, 9, 7, 0.42731133), (509, 9, 8, 0.58918613), (542, 9, 4, 0.7811711), (550, 9, 4, 0.48983827), (606, 9, 4, 0.4486785), (622, 8, 5, 0.44585204), (626, 9, 0, 0.41016862), (637, 9, 5, 0.7727562), (648, 8, 8, 0.54579353), (651, 9, 4, 0.50510496), (669, 9, 7, 0.6597887), (670, 9, 5, 0.59488916), (673, 9, 7, 0.7962353), (719, 9, 4, 0.69263923), (755, 9, 5, 0.68667513), (783, 9, 7, 0.76774544), (789, 9, 5, 0.5064388), (791, 9, 7, 0.6975717), (815, 8, 5, 0.43734246), (838, 9, 5, 0.5443313), (856, 9, 5, 0.6272443), (932, 9, 7, 0.69174707), (965, 9, 7, 0.7010521), (993, 2, 2, 0.72791207), (1000, 9, 7, 0.77150375), (1131, 9, 6, 0.3990249), (1172, 9, 7, 0.54666567), (1176, 4, 4, 0.67297536), (1226, 9, 5, 0.46818075), (1230, 9, 7, 0.69457144), (1232, 9, 6, 0.27349627), (1239, 9, 3, 0.46217686), (1242, 9, 5, 0.5293322), (1256, 9, 4, 0.56247675), (1257, 9, 7, 0.73157674), (1262, 9, 5, 0.43525794), (1313, 9, 3, 0.747587), (1352, 9, 7, 0.7042948), (1374, 9, 7, 0.628604), (1377, 9, 5, 0.77635205), (1424, 9, 1, 0.29619017), (1466, 9, 5, 0.44902757), (1473, 9, 7, 0.7546128), (1521, 9, 5, 0.55632323), (1533, 9, 5, 0.68034095), (1536, 9, 4, 0.5248111), (1555, 9, 4, 0.7454313), (1577, 8, 8, 0.5293907), (1588, 9, 4, 0.72351456), (1600, 9, 7, 0.5169592), (1601, 9, 4, 0.49914715), (1608, 3, 5, 0.7384338), (1623, 9, 7, 0.66099167), (1624, 9, 7, 0.6390299), (1626, 9, 7, 0.6515187), (1711, 9, 7, 0.4799123), (1798, 9, 7, 0.3386908), (1819, 9, 4, 0.57754034), (1853, 9, 4, 0.48684523), (1920, 2, 2, 0.5479177), (1922, 9, 4, 0.66798705), (1949, 9, 4, 0.73387253), (1981, 9, 7, 0.5734509), (2007, 9, 7, 0.6199854), (2009, 4, 6, 0.6561441), (2053, 9, 5, 0.7165863), (2067, 9, 5, 0.6102807), (2069, 9, 4, 0.6415592), (2074, 9, 7, 0.38519713), (2101, 9, 0, 0.55022985), (2125, 8, 8, 0.39163703), (2132, 9, 7, 0.5803958), (2154, 9, 4, 0.5104009), (2235, 9, 1, 0.7306577), (2248, 9, 4, 0.6223345), (2317, 8, 5, 0.51849294), (2319, 8, 3, 0.7014035), (2326, 9, 7, 0.5163476), (2384, 9, 5, 0.3938233), (2447, 8, 8, 0.56680465), (2490, 9, 5, 0.5089864), (2515, 9, 5, 0.60171026), (2527, 9, 4, 0.7012327), (2550, 9, 7, 0.4161116), (2556, 7, 2, 0.552722), (2574, 9, 5, 0.5778703), (2612, 9, 7, 0.7825019), (2616, 9, 4, 0.53799605), (2647, 0, 4, 0.5903054), (2648, 9, 4, 0.71374804), (2685, 9, 7, 0.46627894), (2730, 9, 5, 0.4895226), (2740, 9, 5, 0.5797582), (2749, 9, 4, 0.70949465), (2774, 9, 4, 0.77167475), (2776, 9, 4, 0.39316493), (2834, 9, 7, 0.7051336), (2868, 9, 7, 0.44981694), (2901, 2, 2, 0.44965616), (2924, 9, 4, 0.7007316), (2957, 9, 7, 0.39513898), (2964, 9, 5, 0.77867657), (3041, 9, 5, 0.49402386), (3042, 0, 0, 0.49760315), (3093, 9, 4, 0.5851087), (3103, 2, 2, 0.45893326), (3151, 9, 5, 0.79867226), (3203, 9, 5, 0.4364632), (3227, 9, 4, 0.3973229), (3251, 9, 5, 0.5301226), (3272, 9, 7, 0.44071352), (3313, 9, 4, 0.2700315), (3349, 9, 4, 0.4966704), (3394, 9, 5, 0.5309679), (3395, 9, 4, 0.52519405), (3409, 9, 0, 0.71782786), (3474, 9, 7, 0.41034278), (3494, 9, 7, 0.5614329), (3502, 9, 7, 0.37660894), (3561, 9, 8, 0.46465087), (3572, 9, 7, 0.7689197), (3574, 9, 4, 0.6753696), (3596, 9, 7, 0.6605866), (3602, 9, 5, 0.4945705), (3614, 9, 4, 0.7152451), (3625, 8, 8, 0.37976483), (3643, 9, 2, 0.4261382), (3644, 9, 5, 0.35538125), (3731, 2, 3, 0.6792448), (3757, 9, 7, 0.40497068), (3767, 9, 4, 0.62796956), (3850, 9, 5, 0.65502816), (3862, 9, 5, 0.49915355), (3925, 9, 4, 0.60652643), (3994, 9, 7, 0.5311929), (3999, 9, 5, 0.63838136), (4006, 0, 7, 0.63507587), (4022, 9, 5, 0.38164788), (4038, 9, 4, 0.7945723), (4097, 9, 5, 0.652939), (4119, 8, 5, 0.7583958), (4157, 2, 3, 0.52191037), (4259, 9, 4, 0.30406326), (4333, 9, 5, 0.5032782), (4338, 6, 5, 0.4571005), (4348, 9, 4, 0.5228378), (4399, 9, 5, 0.35759652), (4431, 9, 5, 0.39476034), (4432, 9, 5, 0.6556452), (4440, 9, 7, 0.48251987), (4452, 9, 4, 0.74987495), (4462, 9, 7, 0.6954612), (4492, 9, 4, 0.7483998), (4505, 9, 4, 0.5309844), (4537, 9, 4, 0.4137706), (4555, 7, 7, 0.6955199), (4592, 8, 8, 0.75017333), (4603, 9, 7, 0.65712833), (4699, 9, 4, 0.7201073), (4708, 9, 0, 0.40748116), (4725, 9, 7, 0.5730755), (4727, 9, 7, 0.6844597), (4749, 8, 3, 0.65578526), (4776, 9, 7, 0.7078726), (4805, 9, 5, 0.44574216), (4818, 8, 8, 0.6961768), (4856, 2, 7, 0.5765613), (4907, 9, 1, 0.6641817), (4912, 2, 6, 0.68045974), (4938, 9, 7, 0.40351316), (4956, 8, 6, 0.55176175), (4961, 3, 7, 0.7747407), (4965, 9, 7, 0.73476595), (4981, 9, 4, 0.6073386), (5021, 9, 4, 0.7173075), (5086, 8, 5, 0.6644551), (5115, 9, 4, 0.49819562), (5126, 8, 8, 0.6233368), (5175, 9, 5, 0.36712888), (5177, 9, 7, 0.65666616), (5183, 9, 4, 0.6604431), (5212, 9, 5, 0.68693304), (5277, 9, 4, 0.33204445), (5294, 3, 3, 0.78114474), (5295, 9, 7, 0.5646749), (5302, 9, 7, 0.2744725), (5305, 9, 5, 0.5829904), (5419, 9, 7, 0.67365676), (5426, 9, 7, 0.60013926), (5428, 9, 7, 0.5905974), (5466, 8, 8, 0.78023624), (5493, 9, 5, 0.72924787), (5536, 9, 5, 0.5041644), (5547, 9, 4, 0.58853316), (5575, 2, 7, 0.7879131), (5658, 8, 8, 0.5577073), (5693, 8, 8, 0.5470328), (5698, 9, 7, 0.56398046), (5711, 2, 7, 0.7391989), (5715, 6, 1, 0.7957664), (5729, 9, 5, 0.75184554), (5774, 5, 3, 0.5383349), (5786, 9, 7, 0.56539655), (5940, 9, 4, 0.7615251), (5953, 9, 7, 0.5879369), (5961, 9, 4, 0.7412711), (5962, 9, 5, 0.4134718), (5976, 9, 5, 0.60471064), (6013, 9, 4, 0.7704663), (6018, 9, 5, 0.4408446), (6038, 9, 4, 0.6245935), (6067, 9, 0, 0.71764475), (6134, 9, 5, 0.7758373), (6182, 9, 5, 0.71744585), (6206, 9, 7, 0.75489), (6221, 9, 7, 0.62323594), (6231, 8, 8, 0.6032198), (6256, 9, 5, 0.47978213), (6317, 9, 7, 0.598421), (6322, 9, 4, 0.30223858), (6334, 9, 5, 0.41154894), (6344, 9, 0, 0.3564089), (6358, 9, 5, 0.5794566), (6410, 9, 5, 0.77854013), (6424, 8, 8, 0.79072464), (6454, 9, 0, 0.50802577), (6459, 9, 4, 0.50488394), (6463, 2, 7, 0.7025869), (6515, 9, 4, 0.7952438), (6555, 9, 4, 0.62090623), (6584, 2, 2, 0.28901476), (6614, 9, 7, 0.76611835), (6663, 9, 4, 0.52884907), (6679, 9, 5, 0.4634688), (6682, 8, 8, 0.7293166), (6685, 9, 5, 0.47759628), (6690, 9, 7, 0.5650044), (6693, 9, 4, 0.71326125), (6695, 8, 5, 0.37777057), (6702, 9, 4, 0.6099156), (6711, 9, 5, 0.27998084), (6736, 9, 5, 0.42446318), (6755, 9, 5, 0.7909876), (6783, 9, 3, 0.45224288), (6812, 8, 8, 0.4465607), (6842, 9, 4, 0.44396976), (6854, 9, 5, 0.73986167), (6869, 9, 5, 0.70439345), (6875, 2, 7, 0.681462), (6903, 9, 4, 0.5435487), (6979, 9, 4, 0.52281934), (6984, 9, 5, 0.6720578), (7070, 9, 5, 0.60134417), (7084, 8, 8, 0.4653552), (7087, 9, 4, 0.47387835), (7108, 9, 7, 0.5757903), (7117, 0, 0, 0.61330414), (7141, 9, 5, 0.7924525), (7221, 9, 0, 0.783738), (7255, 9, 5, 0.685994), (7283, 9, 5, 0.3166903), (7345, 9, 0, 0.7356041), (7372, 9, 4, 0.57598656), (7396, 9, 4, 0.7898574), (7445, 8, 3, 0.46473747), (7543, 9, 4, 0.59532726), (7572, 9, 7, 0.4425898), (7612, 6, 6, 0.3865812), (7661, 9, 7, 0.6898585), (7677, 9, 7, 0.37369847), (7723, 9, 4, 0.5947021), (7725, 9, 7, 0.45379144), (7734, 9, 7, 0.5633518), (7741, 8, 4, 0.58640194), (7751, 9, 7, 0.55273956), (7760, 8, 3, 0.57194096), (7765, 2, 2, 0.7637563), (7771, 9, 4, 0.55011255), (7787, 9, 5, 0.4877451), (7791, 7, 7, 0.7077925), (7801, 8, 8, 0.65830636), (7809, 1, 1, 0.65600955), (7835, 9, 5, 0.6705353), (7915, 9, 2, 0.4134667), (7953, 9, 5, 0.39631224), (7978, 9, 5, 0.50524324), (7984, 9, 4, 0.44753116), (8008, 2, 2, 0.75825286), (8028, 9, 3, 0.45990568), (8045, 9, 7, 0.63680273), (8068, 3, 3, 0.56586087), (8083, 9, 5, 0.45749974), (8125, 9, 5, 0.39412415), (8144, 9, 4, 0.61830276), (8172, 8, 8, 0.6330883), (8176, 9, 5, 0.6472161), (8192, 7, 5, 0.43129814), (8213, 2, 7, 0.7844961), (8236, 9, 7, 0.729709), (8253, 9, 5, 0.4272774), (8281, 9, 7, 0.7138531), (8286, 8, 8, 0.75192153), (8302, 9, 7, 0.5097059), (8340, 9, 4, 0.72719735), (8354, 3, 3, 0.6587243), (8363, 9, 5, 0.57108945), (8378, 9, 5, 0.38658866), (8398, 9, 4, 0.3112373), (8410, 9, 7, 0.7142048), (8452, 8, 6, 0.6307019), (8512, 9, 8, 0.7759514), (8519, 9, 7, 0.4485742), (8544, 9, 5, 0.68865454), (8548, 9, 7, 0.78139555), (8558, 8, 3, 0.5608524), (8559, 9, 5, 0.60021615), (8566, 2, 1, 0.4720378), (8568, 9, 4, 0.4528044), (8583, 9, 5, 0.5115869), (8625, 9, 4, 0.50563926), (8641, 9, 5, 0.35473487), (8651, 9, 5, 0.66908437), (8656, 9, 8, 0.21057786), (8718, 9, 8, 0.51828396), (8742, 9, 4, 0.6652016), (8783, 9, 6, 0.45421466), (8786, 8, 3, 0.5616191), (8788, 9, 4, 0.766451), (8789, 9, 4, 0.32732183), (8795, 9, 7, 0.40532735), (8802, 9, 5, 0.6229285), (8815, 9, 5, 0.4351317), (8842, 8, 3, 0.466071), (8844, 9, 7, 0.67047364), (8851, 9, 5, 0.34934473), (8855, 8, 3, 0.75836617), (8874, 9, 5, 0.5841426), (8920, 9, 2, 0.75524426), (8923, 9, 5, 0.546738), (8924, 8, 5, 0.46105856), (8928, 2, 2, 0.6447079), (8941, 9, 4, 0.4770673), (8953, 9, 0, 0.28728876), (8966, 1, 1, 0.7335397), (9025, 9, 5, 0.66837054), (9031, 9, 8, 0.69092846), (9066, 9, 4, 0.79490364), (9097, 9, 0, 0.60065), (9130, 0, 6, 0.75975686), (9160, 5, 3, 0.7921216), (9188, 9, 5, 0.61490965), (9200, 8, 4, 0.7488306), (9212, 9, 7, 0.5391186), (9278, 9, 5, 0.46930566), (9282, 8, 8, 0.5506491), (9298, 9, 4, 0.5393996), (9358, 9, 8, 0.44683534), (9383, 8, 8, 0.6815126), (9419, 9, 4, 0.58238906), (9458, 9, 4, 0.38137144), (9461, 9, 2, 0.74124676), (9481, 9, 7, 0.37537196), (9511, 0, 2, 0.77428824), (9528, 9, 7, 0.38203123), (9591, 9, 7, 0.6228303), (9600, 9, 7, 0.74336094), (9610, 9, 7, 0.6959019), (9700, 9, 7, 0.5830526), (9706, 9, 4, 0.50773495), (9729, 2, 3, 0.5440449), (9767, 9, 4, 0.45258823), (9785, 0, 0, 0.7656365), (9795, 9, 4, 0.7854926), (9819, 8, 3, 0.78732246), (9869, 9, 4, 0.56654555), (9871, 9, 7, 0.76910883), (9955, 0, 0, 0.7546804), (9993, 9, 3, 0.5016635)]\n",
            "[(68, 9, 9, 0.36073866), (88, 9, 9, 0.54358953), (125, 9, 9, 0.46659192), (149, 9, 9, 0.5654679), (176, 9, 9, 0.65573764), (236, 9, 9, 0.7288132), (319, 9, 9, 0.70804584), (320, 9, 9, 0.6563065), (322, 9, 9, 0.56559986), (327, 9, 9, 0.62139213), (347, 9, 9, 0.6404826), (378, 9, 9, 0.44418088), (429, 9, 9, 0.39046547), (444, 9, 9, 0.42731133), (509, 9, 9, 0.58918613), (542, 9, 9, 0.7811711), (550, 9, 9, 0.48983827), (606, 9, 9, 0.4486785), (626, 9, 9, 0.41016862), (637, 9, 9, 0.7727562), (651, 9, 9, 0.50510496), (669, 9, 9, 0.6597887), (670, 9, 9, 0.59488916), (673, 9, 9, 0.7962353), (719, 9, 9, 0.69263923), (755, 9, 9, 0.68667513), (783, 9, 9, 0.76774544), (789, 9, 9, 0.5064388), (791, 9, 9, 0.6975717), (838, 9, 9, 0.5443313), (856, 9, 9, 0.6272443), (932, 9, 9, 0.69174707), (965, 9, 9, 0.7010521), (1000, 9, 9, 0.77150375), (1131, 9, 9, 0.3990249), (1172, 9, 9, 0.54666567), (1226, 9, 9, 0.46818075), (1230, 9, 9, 0.69457144), (1232, 9, 9, 0.27349627), (1239, 9, 9, 0.46217686), (1242, 9, 9, 0.5293322), (1256, 9, 9, 0.56247675), (1257, 9, 9, 0.73157674), (1262, 9, 9, 0.43525794), (1313, 9, 9, 0.747587), (1352, 9, 9, 0.7042948), (1374, 9, 9, 0.628604), (1377, 9, 9, 0.77635205), (1424, 9, 9, 0.29619017), (1466, 9, 9, 0.44902757), (1473, 9, 9, 0.7546128), (1521, 9, 9, 0.55632323), (1533, 9, 9, 0.68034095), (1536, 9, 9, 0.5248111), (1555, 9, 9, 0.7454313), (1588, 9, 9, 0.72351456), (1600, 9, 9, 0.5169592), (1601, 9, 9, 0.49914715), (1623, 9, 9, 0.66099167), (1624, 9, 9, 0.6390299), (1626, 9, 9, 0.6515187), (1711, 9, 9, 0.4799123), (1798, 9, 9, 0.3386908), (1819, 9, 9, 0.57754034), (1853, 9, 9, 0.48684523), (1922, 9, 9, 0.66798705), (1949, 9, 9, 0.73387253), (1981, 9, 9, 0.5734509), (2007, 9, 9, 0.6199854), (2053, 9, 9, 0.7165863), (2067, 9, 9, 0.6102807), (2069, 9, 9, 0.6415592), (2074, 9, 9, 0.38519713), (2101, 9, 9, 0.55022985), (2132, 9, 9, 0.5803958), (2154, 9, 9, 0.5104009), (2235, 9, 9, 0.7306577), (2248, 9, 9, 0.6223345), (2326, 9, 9, 0.5163476), (2384, 9, 9, 0.3938233), (2490, 9, 9, 0.5089864), (2515, 9, 9, 0.60171026), (2527, 9, 9, 0.7012327), (2550, 9, 9, 0.4161116), (2574, 9, 9, 0.5778703), (2612, 9, 9, 0.7825019), (2616, 9, 9, 0.53799605), (2648, 9, 9, 0.71374804), (2685, 9, 9, 0.46627894), (2730, 9, 9, 0.4895226), (2740, 9, 9, 0.5797582), (2749, 9, 9, 0.70949465), (2774, 9, 9, 0.77167475), (2776, 9, 9, 0.39316493), (2834, 9, 9, 0.7051336), (2868, 9, 9, 0.44981694), (2924, 9, 9, 0.7007316), (2957, 9, 9, 0.39513898), (2964, 9, 9, 0.77867657), (3041, 9, 9, 0.49402386), (3093, 9, 9, 0.5851087), (3151, 9, 9, 0.79867226), (3203, 9, 9, 0.4364632), (3227, 9, 9, 0.3973229), (3251, 9, 9, 0.5301226), (3272, 9, 9, 0.44071352), (3313, 9, 9, 0.2700315), (3349, 9, 9, 0.4966704), (3394, 9, 9, 0.5309679), (3395, 9, 9, 0.52519405), (3409, 9, 9, 0.71782786), (3474, 9, 9, 0.41034278), (3494, 9, 9, 0.5614329), (3502, 9, 9, 0.37660894), (3561, 9, 9, 0.46465087), (3572, 9, 9, 0.7689197), (3574, 9, 9, 0.6753696), (3596, 9, 9, 0.6605866), (3602, 9, 9, 0.4945705), (3614, 9, 9, 0.7152451), (3643, 9, 9, 0.4261382), (3644, 9, 9, 0.35538125), (3757, 9, 9, 0.40497068), (3767, 9, 9, 0.62796956), (3850, 9, 9, 0.65502816), (3862, 9, 9, 0.49915355), (3925, 9, 9, 0.60652643), (3994, 9, 9, 0.5311929), (3999, 9, 9, 0.63838136), (4022, 9, 9, 0.38164788), (4038, 9, 9, 0.7945723), (4097, 9, 9, 0.652939), (4259, 9, 9, 0.30406326), (4333, 9, 9, 0.5032782), (4348, 9, 9, 0.5228378), (4399, 9, 9, 0.35759652), (4431, 9, 9, 0.39476034), (4432, 9, 9, 0.6556452), (4440, 9, 9, 0.48251987), (4452, 9, 9, 0.74987495), (4462, 9, 9, 0.6954612), (4492, 9, 9, 0.7483998), (4505, 9, 9, 0.5309844), (4537, 9, 9, 0.4137706), (4603, 9, 9, 0.65712833), (4699, 9, 9, 0.7201073), (4708, 9, 9, 0.40748116), (4725, 9, 9, 0.5730755), (4727, 9, 9, 0.6844597), (4776, 9, 9, 0.7078726), (4805, 9, 9, 0.44574216), (4907, 9, 9, 0.6641817), (4938, 9, 9, 0.40351316), (4965, 9, 9, 0.73476595), (4981, 9, 9, 0.6073386), (5021, 9, 9, 0.7173075), (5115, 9, 9, 0.49819562), (5175, 9, 9, 0.36712888), (5177, 9, 9, 0.65666616), (5183, 9, 9, 0.6604431), (5212, 9, 9, 0.68693304), (5277, 9, 9, 0.33204445), (5295, 9, 9, 0.5646749), (5302, 9, 9, 0.2744725), (5305, 9, 9, 0.5829904), (5419, 9, 9, 0.67365676), (5426, 9, 9, 0.60013926), (5428, 9, 9, 0.5905974), (5493, 9, 9, 0.72924787), (5536, 9, 9, 0.5041644), (5547, 9, 9, 0.58853316), (5698, 9, 9, 0.56398046), (5729, 9, 9, 0.75184554), (5786, 9, 9, 0.56539655), (5940, 9, 9, 0.7615251), (5953, 9, 9, 0.5879369), (5961, 9, 9, 0.7412711), (5962, 9, 9, 0.4134718), (5976, 9, 9, 0.60471064), (6013, 9, 9, 0.7704663), (6018, 9, 9, 0.4408446), (6038, 9, 9, 0.6245935), (6067, 9, 9, 0.71764475), (6134, 9, 9, 0.7758373), (6182, 9, 9, 0.71744585), (6206, 9, 9, 0.75489), (6221, 9, 9, 0.62323594), (6256, 9, 9, 0.47978213), (6317, 9, 9, 0.598421), (6322, 9, 9, 0.30223858), (6334, 9, 9, 0.41154894), (6344, 9, 9, 0.3564089), (6358, 9, 9, 0.5794566), (6410, 9, 9, 0.77854013), (6454, 9, 9, 0.50802577), (6459, 9, 9, 0.50488394), (6515, 9, 9, 0.7952438), (6555, 9, 9, 0.62090623), (6614, 9, 9, 0.76611835), (6663, 9, 9, 0.52884907), (6679, 9, 9, 0.4634688), (6685, 9, 9, 0.47759628), (6690, 9, 9, 0.5650044), (6693, 9, 9, 0.71326125), (6702, 9, 9, 0.6099156), (6711, 9, 9, 0.27998084), (6736, 9, 9, 0.42446318), (6755, 9, 9, 0.7909876), (6783, 9, 9, 0.45224288), (6842, 9, 9, 0.44396976), (6854, 9, 9, 0.73986167), (6869, 9, 9, 0.70439345), (6903, 9, 9, 0.5435487), (6979, 9, 9, 0.52281934), (6984, 9, 9, 0.6720578), (7070, 9, 9, 0.60134417), (7087, 9, 9, 0.47387835), (7108, 9, 9, 0.5757903), (7141, 9, 9, 0.7924525), (7221, 9, 9, 0.783738), (7255, 9, 9, 0.685994), (7283, 9, 9, 0.3166903), (7345, 9, 9, 0.7356041), (7372, 9, 9, 0.57598656), (7396, 9, 9, 0.7898574), (7543, 9, 9, 0.59532726), (7572, 9, 9, 0.4425898), (7661, 9, 9, 0.6898585), (7677, 9, 9, 0.37369847), (7723, 9, 9, 0.5947021), (7725, 9, 9, 0.45379144), (7734, 9, 9, 0.5633518), (7751, 9, 9, 0.55273956), (7771, 9, 9, 0.55011255), (7787, 9, 9, 0.4877451), (7835, 9, 9, 0.6705353), (7915, 9, 9, 0.4134667), (7953, 9, 9, 0.39631224), (7978, 9, 9, 0.50524324), (7984, 9, 9, 0.44753116), (8028, 9, 9, 0.45990568), (8045, 9, 9, 0.63680273), (8083, 9, 9, 0.45749974), (8125, 9, 9, 0.39412415), (8144, 9, 9, 0.61830276), (8176, 9, 9, 0.6472161), (8236, 9, 9, 0.729709), (8253, 9, 9, 0.4272774), (8281, 9, 9, 0.7138531), (8302, 9, 9, 0.5097059), (8340, 9, 9, 0.72719735), (8363, 9, 9, 0.57108945), (8378, 9, 9, 0.38658866), (8398, 9, 9, 0.3112373), (8410, 9, 9, 0.7142048), (8512, 9, 9, 0.7759514), (8519, 9, 9, 0.4485742), (8544, 9, 9, 0.68865454), (8548, 9, 9, 0.78139555), (8559, 9, 9, 0.60021615), (8568, 9, 9, 0.4528044), (8583, 9, 9, 0.5115869), (8625, 9, 9, 0.50563926), (8641, 9, 9, 0.35473487), (8651, 9, 9, 0.66908437), (8656, 9, 9, 0.21057786), (8718, 9, 9, 0.51828396), (8742, 9, 9, 0.6652016), (8783, 9, 9, 0.45421466), (8788, 9, 9, 0.766451), (8789, 9, 9, 0.32732183), (8795, 9, 9, 0.40532735), (8802, 9, 9, 0.6229285), (8815, 9, 9, 0.4351317), (8844, 9, 9, 0.67047364), (8851, 9, 9, 0.34934473), (8874, 9, 9, 0.5841426), (8920, 9, 9, 0.75524426), (8923, 9, 9, 0.546738), (8941, 9, 9, 0.4770673), (8953, 9, 9, 0.28728876), (9025, 9, 9, 0.66837054), (9031, 9, 9, 0.69092846), (9066, 9, 9, 0.79490364), (9097, 9, 9, 0.60065), (9188, 9, 9, 0.61490965), (9212, 9, 9, 0.5391186), (9278, 9, 9, 0.46930566), (9298, 9, 9, 0.5393996), (9358, 9, 9, 0.44683534), (9419, 9, 9, 0.58238906), (9458, 9, 9, 0.38137144), (9461, 9, 9, 0.74124676), (9481, 9, 9, 0.37537196), (9528, 9, 9, 0.38203123), (9591, 9, 9, 0.6228303), (9600, 9, 9, 0.74336094), (9610, 9, 9, 0.6959019), (9700, 9, 9, 0.5830526), (9706, 9, 9, 0.50773495), (9767, 9, 9, 0.45258823), (9795, 9, 9, 0.7854926), (9869, 9, 9, 0.56654555), (9871, 9, 9, 0.76910883), (9993, 9, 9, 0.5016635)]\n",
            "394\n",
            "305\n",
            "[[ 969    0    2    0    1    2    3    3    0    0]\n",
            " [   0 1134    0    1    0    0    0    0    0    0]\n",
            " [   1    3  988    7    1    0    1   31    0    0]\n",
            " [   0    0    0 1002    0    5    0    3    0    0]\n",
            " [   0    1    0    0  979    0    2    0    0    0]\n",
            " [   0    0    0    4    0  887    1    0    0    0]\n",
            " [   0    6    0    0    1    4  947    0    0    0]\n",
            " [   0    5    2    0    0    1    0 1020    0    0]\n",
            " [   1    0    1   23    4   20    6    4  915    0]\n",
            " [  17    3    2    7  262  185    0  227    1  305]]\n",
            "Precision: %d 0.9283068423138072\n",
            "Recall: %d 0.915111781106716\n",
            "F1 Score: %d 0.899455095435\n",
            "Optimal temperature: 0.164\n",
            "After temperature - NLL: 0.579, ECE: 0.076\n",
            "Anomaly Count: 394\n",
            "Temperature scaled model saved to %s model_with_temperature.pth\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wPwAyxghVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
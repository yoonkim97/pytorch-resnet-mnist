{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqCVhGKK0jsHArHt+BySvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonkim97/pytorch-resnet-mnist/blob/master/MNISTResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4kKlVC_gUac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
        "import inspect\n",
        "import time\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "import urllib\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import BatchSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as5am2P6cF3P",
        "colab_type": "code",
        "outputId": "bac7c921-8716-4714-9a55-d424b2b0746b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "\n",
        "num_workers = 0\n",
        "batch_size = 20\n",
        "basepath = '.'\n",
        "\n",
        "def set_header_for(url, filename):\n",
        "    opener = urllib.request.URLopener()\n",
        "    opener.addheader('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36')\n",
        "    opener.retrieve(\n",
        "    url, f'{basepath}/{filename}')\n",
        "\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
        "set_header_for('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: URLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EyYP1Oshued",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistResNet(ResNet):\n",
        "  def __init__(self):\n",
        "    super(MnistResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "    self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "  def forward(self, x):\n",
        "    return torch.softmax(super(MnistResNet, self).forward(x), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjriG1vnd8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_label_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "def get_same_indices(target, labels):\n",
        "  label_indices = []\n",
        "  for i in range (len(target)):\n",
        "    for j in range (len(labels)):\n",
        "      if target[i] == labels[j]:\n",
        "        label_indices.append(i)\n",
        "  return label_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz1J1M5wiK8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loaders(train_batch_size, val_batch_size):\n",
        "  mnist = MNIST(download=True, train=True, root=\".\").train_data.float()\n",
        "    \n",
        "  data_transform = Compose([Resize((224, 224)),ToTensor(), Normalize((mnist.mean()/255,), (mnist.std()/255,))])\n",
        "\n",
        "  train_dataset = MNIST(download=True, root=\".\", transform=data_transform, train=True)\n",
        "  train_indices = get_same_indices(train_dataset.targets, train_label_classes)\n",
        "  train_loader = DataLoader(dataset = train_dataset, batch_size=train_batch_size, shuffle=False, sampler=torch.utils.data.sampler.SubsetRandomSampler(train_indices))\n",
        "\n",
        "  val_dataset = MNIST(download=False, root=\".\", transform=data_transform, train=False)\n",
        "  # val_indices = get_same_indices(val_dataset.targets, test_label_classes)\n",
        "  val_classes = [100, 100, 100, 100, 100, 100, 100, 100, 100, 13]\n",
        "  weights = 1 / torch.Tensor(val_classes)\n",
        "  val_loader = DataLoader(dataset = val_dataset, batch_size=val_batch_size, shuffle=False, sampler=torch.utils.data.sampler.WeightedRandomSampler(weights, val_batch_size))\n",
        "  return train_loader, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioMn7cELiRFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_metric(metric_fn, true_y, pred_y):\n",
        "  if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "    return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "  else:\n",
        "    return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def print_scores(p, r, f1, a, batch_size):\n",
        "  for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "    print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtBAg820iazl",
        "colab_type": "code",
        "outputId": "f5f8ba47-5e55-4fe1-e3a4-75d95556eb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "start_ts = time.time()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 5\n",
        "\n",
        "model = MnistResNet().to(device)\n",
        "train_loader, val_loader = get_data_loaders(256, 256)\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "#training loop\n",
        "# for epoch in range(epochs):\n",
        "#     total_loss = 0\n",
        "#     progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "#     model.train()\n",
        "    \n",
        "#     for i, data in progress:\n",
        "#         X, y = data[0].to(device), data[1].to(device)\n",
        "#         model.zero_grad()\n",
        "#         outputs = model(X)\n",
        "#         loss = loss_function(outputs, y)\n",
        "\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         current_loss = loss.item()\n",
        "#         total_loss += current_loss\n",
        "#         progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "#     torch.cuda.empty_cache()\n",
        "    \n",
        "#     print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}\")\n",
        "#     losses.append(total_loss/batches)\n",
        "#     print(losses)\n",
        "#     print(f\"Training time: {time.time()-start_ts}s\")\n",
        "#     model_filename = 'model.pth'\n",
        "#     torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "val_losses = 0\n",
        "precision, recall, f1, accuracy = [], [], [], []\n",
        "\n",
        "confusion_actuals = []\n",
        "probabilities = []\n",
        "predictions = []\n",
        "roc_actuals = []\n",
        "\n",
        "which_class = 9\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\"))\n",
        "# validation loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        y_np = y.cpu().numpy()\n",
        "\n",
        "        x_val_zeros = X[y_np == 0]\n",
        "        x_val_ones = X[y_np== 1]\n",
        "        x_val_twos = X[y_np == 2]\n",
        "        x_val_threes = X[y_np == 3]\n",
        "        x_val_fours = X[y_np == 4]\n",
        "        x_val_fives = X[y_np == 5]\n",
        "        x_val_sixes = X[y_np == 6]\n",
        "        x_val_sevens = X[y_np == 7]\n",
        "        x_val_eights = X[y_np == 8]\n",
        "        x_val_nines = X[y_np == 9]\n",
        "\n",
        "        print(len(x_val_zeros), len(x_val_ones), len(x_val_twos), len(x_val_threes), len(x_val_fours), len(x_val_fives), len(x_val_sixes), len(x_val_sevens), len(x_val_eights), len(x_val_nines))\n",
        "        outputs = model(X)\n",
        "        prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "        confusion_actuals.extend(y.view_as(prediction))\n",
        "        roc_actuals.extend(y.view_as(prediction) == which_class)\n",
        "        probabilities.extend(np.exp(outputs.cpu()[:, which_class]))  \n",
        "        predictions.extend(prediction)\n",
        "\n",
        "        val_losses += loss_function(outputs, y)\n",
        "\n",
        "        predicted_classes = torch.max(outputs, 1)[1]\n",
        "        \n",
        "        for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "                                (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "            acc.append(\n",
        "                calculate_metric(metric, y.cpu(), predicted_classes.cpu())\n",
        "            )\n",
        "\n",
        "confusion_actuals = [i.item() for i in confusion_actuals]\n",
        "predictions = [i.item() for i in predictions]\n",
        "roc_actuals = [i.item() for i in roc_actuals]\n",
        "class_probabilities = [i.item() for i in probabilities]\n",
        "\n",
        "confusion_mtrx = confusion_matrix(confusion_actuals, predictions)\n",
        "\n",
        "FP = confusion_mtrx.sum(axis=0) - np.diag(confusion_mtrx)  \n",
        "FN = confusion_mtrx.sum(axis=1) - np.diag(confusion_mtrx)\n",
        "TP = np.diag(confusion_mtrx)\n",
        "TN = confusion_mtrx.sum() - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "\n",
        "print(confusion_mtrx)\n",
        "print(\"FP\", FP)\n",
        "print(\"FN\", FN)\n",
        "print(\"TP\", TP)\n",
        "print(\"TN\", TN)\n",
        "\n",
        "print(\"TPR\", TPR)\n",
        "print(\"FPR\", FPR)\n",
        "\n",
        "# plt.plot(FPR, TPR)\n",
        "# plt.show()\n",
        "# auc = np.trapz(TPR,FPR)\n",
        "# print('auc', auc)\n",
        "# fpr, tpr, _ = roc_curve(roc_actuals, class_probabilities)\n",
        "# print(\"actuals\", roc_actuals)\n",
        "# print(\"class_probabilities\", class_probabilities)\n",
        "# roc_auc = auc(fpr, tpr)\n",
        "# print(roc_auc)\n",
        "# plt.figure()\n",
        "# lw = 2 \n",
        "# plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "# plt.plot([0, 1], [0, 1], color = 'navy', lw=lw, linestyle='--')\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False Positive Rate')\n",
        "# plt.ylabel('True Positive Rate')\n",
        "# plt.title('ROC for digit=%d class' % which_class)\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()    \n",
        "print_scores(precision, recall, f1, accuracy, val_batches)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13 36 13 0 41 17 0 12 0 124\n",
            "[[ 13   0   0   0   0   0   0]\n",
            " [  0  36   0   0   0   0   0]\n",
            " [  0   0  13   0   0   0   0]\n",
            " [  0   0   0  41   0   0   0]\n",
            " [  0   0   0   0  17   0   0]\n",
            " [  0   0   0   0   0  12   0]\n",
            " [  0   0   0 124   0   0   0]]\n",
            "FP [  0   0   0 124   0   0   0]\n",
            "FN [  0   0   0   0   0   0 124]\n",
            "TP [13 36 13 41 17 12  0]\n",
            "TN [243 220 243  91 239 244 132]\n",
            "TPR [1. 1. 1. 1. 1. 1. 0.]\n",
            "FPR [0.         0.         0.         0.57674419 0.         0.\n",
            " 0.        ]\n",
            "\t     precision: 0.7498\n",
            "\t        recall: 0.8571\n",
            "\t            F1: 0.7712\n",
            "\t      accuracy: 0.5156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LcYEyEgYLc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "73bc31c2-97a9-4f95-8d34-764b564ad73c"
      },
      "source": [
        "class ModelWithTemperature(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super(ModelWithTemperature, self).__init__()\n",
        "        self.model = model\n",
        "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
        "\n",
        "    def forward(self, input):\n",
        "        logits = self.model(input)\n",
        "        return self.temperature_scale(logits)\n",
        "\n",
        "    def temperature_scale(self, logits):\n",
        "        \"\"\"\n",
        "        Perform temperature scaling on logits\n",
        "        \"\"\"\n",
        "        # Expand temperature to match the size of logits\n",
        "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "        return logits / temperature\n",
        "\n",
        "    def set_temperature(self, valid_loader):\n",
        "        self.cuda()\n",
        "        nll_criterion = nn.CrossEntropyLoss().cuda()\n",
        "        ece_criterion = _ECELoss().cuda()\n",
        "        anomaly_criterion = _AnomalyDetection().cuda()\n",
        "\n",
        "        # First: collect all the logits and labels for the validation set\n",
        "        logits_list = []\n",
        "        labels_list = []\n",
        "        with torch.no_grad():\n",
        "            for input, label in valid_loader:\n",
        "                input = input.cuda()\n",
        "                logits = self.model(input)\n",
        "                logits_list.append(logits)\n",
        "                labels_list.append(label)\n",
        "            logits = torch.cat(logits_list).cuda()\n",
        "            labels = torch.cat(labels_list).cuda()\n",
        "\n",
        "        # Calculate NLL and ECE before temperature scaling\n",
        "        # before_temperature_nll = nll_criterion(logits, labels).item()\n",
        "        # before_temperature_ece = ece_criterion(logits, labels).item()\n",
        "        # print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
        "\n",
        "        # Next: optimize the temperature w.r.t. NLL\n",
        "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
        "\n",
        "        def eval():\n",
        "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "        optimizer.step(eval)\n",
        "\n",
        "        # Calculate NLL and ECE after temperature scaling\n",
        "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
        "        after_temperature_anomaly = anomaly_criterion(self.temperature_scale(logits), labels)\n",
        "        print('Optimal temperature: %.3f' % self.temperature.item())\n",
        "        print('After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece))\n",
        "        print('Anomaly Count: %d' %after_temperature_anomaly)\n",
        "        return self"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-82b1bffd8b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModelWithTemperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelWithTemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpY41R6ffj5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _ECELoss(nn.Module):\n",
        "    def __init__(self, n_bins=15):\n",
        "        \"\"\"\n",
        "        n_bins (int): number of confidence interval bins\n",
        "        \"\"\"\n",
        "        super(_ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "      with torch.no_grad():\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "    \n",
        "      ece = torch.zeros(1, device=logits.device)\n",
        "      for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "          # Calculated |confidence - accuracy| in each bin\n",
        "          in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "          prop_in_bin = in_bin.float().mean()\n",
        "          if prop_in_bin.item() > 0:\n",
        "              accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "              avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "              ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "      return ece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjn-A0MWjmoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _AnomalyDetection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(_AnomalyDetection, self).__init__()\n",
        "  def forward(self, logits, labels):\n",
        "    with torch.no_grad():\n",
        "      softmaxes = F.softmax(logits, dim=1)\n",
        "      confidences, predictions = torch.max(softmaxes, 1)\n",
        "      accuracies = predictions.eq(labels)\n",
        "\n",
        "    predictions_list = predictions.cpu().numpy()\n",
        "    confidences_list = confidences.cpu().numpy()\n",
        "    actuals_list = labels.cpu().numpy()\n",
        "\n",
        "    all_triples = []\n",
        "    anomaly_triples = []\n",
        "    modified_anomaly_triples = []\n",
        "\n",
        "    anomaly_count = 0\n",
        "    for i in range(len(actuals_list)):\n",
        "      all_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "      if (confidences_list[i] < 0.7):\n",
        "        anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        if (actuals_list[i] == 9):\n",
        "          predictions_list[i] = 9\n",
        "          modified_anomaly_triples.append((i, actuals_list[i], predictions_list[i], confidences_list[i]))\n",
        "        anomaly_count += 1\n",
        "    print(\"all triples : \", all_triples)\n",
        "    # print(\"length of all triples: \", len(all_triples))\n",
        "    print(\"anomaly triples: \", anomaly_triples)\n",
        "    # print(\"length of anomaly triples: \", len(anomaly_triples))\n",
        "    print(\"modified anomaly triples:\", modified_anomaly_triples)\n",
        "    # print(len(anomaly_triples))\n",
        "    # print(len(modified_anomaly_triples))\n",
        "\n",
        "    conf_matrix = confusion_matrix(actuals_list, predictions_list)\n",
        "    precision = precision_score(actuals_list, predictions_list, average='macro')\n",
        "    recall = recall_score(actuals_list, predictions_list, average='macro')\n",
        "    f1 = f1_score(actuals_list, predictions_list, average='macro')\n",
        "    print(conf_matrix) \n",
        "    print(\"Precision: %d\", precision)\n",
        "    print(\"Recall: %d\", recall)\n",
        "    print(\"F1 Score: %d\", f1)\n",
        "    \n",
        "\n",
        "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  \n",
        "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
        "    TP = np.diag(conf_matrix)\n",
        "    TN = conf_matrix.sum() - (FP + FN + TP)\n",
        "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    # # Sensitivity, hit rate, recall, or true positive rate\n",
        "    # TPR = TP/(TP+FN)\n",
        "    # # Specificity or true negative rate\n",
        "    # TNR = TN/(TN+FP) \n",
        "    # # Precision or positive predictive value\n",
        "    # PPV = TP/(TP+FP)\n",
        "    # # Negative predictive value\n",
        "    # NPV = TN/(TN+FN)\n",
        "    # # Fall out or false positive rate\n",
        "    # FPR = FP/(FP+TN)\n",
        "    # # False negative rate\n",
        "    # FNR = FN/(TP+FN)\n",
        "    # # False discovery rate\n",
        "    # FDR = FP/(TP+FP)\n",
        "\n",
        "    # # Overall accuracy\n",
        "    # ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    return anomaly_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChW2cvo8fmKj",
        "colab_type": "code",
        "outputId": "ccf7c8a4-6dd0-44a5-8f9d-cc21dfcac8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "scaled_model = ModelWithTemperature(model)\n",
        "scaled_model.set_temperature(val_loader)\n",
        "\n",
        "\n",
        "anomaly_class = 9 \n",
        "actuals = []\n",
        "class_probabilities = []\n",
        "# # for i in range(len(actuals_list)):\n",
        "# #   if (actuals_list[i] == anomaly_class):\n",
        "# #     actuals.append(True)\n",
        "# #   else:\n",
        "# #     actuals.append(False)\n",
        "\n",
        "scaled_model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(val_loader):\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        print(y.cpu().numpy())\n",
        "        outputs = scaled_model(X)\n",
        "        prediction = outputs.argmax(dim=1, keepdim=True)\n",
        "        actuals.extend(y.view_as(prediction) == anomaly_class)\n",
        "        class_probabilities.extend(np.exp(outputs.cpu()[:, anomaly_class])) \n",
        "      \n",
        "print(class_probabilities)\n",
        "# print(\"prediction\", prediction)\n",
        "# print(\"prediction len\", len(prediction))\n",
        "# print(\"actual len\", len(actuals))\n",
        "\n",
        "actuals = [i.item() for i in actuals]\n",
        "probabilities = [i.item() for i in class_probabilities]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(actuals, probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)\n",
        "plt.figure()\n",
        "lw = 2 \n",
        "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color = 'navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for digit=%d class' % which_class)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "model_filename = 'model_with_temperature.pth'\n",
        "torch.save(scaled_model.state_dict(), model_filename)\n",
        "print('Temperature scaled model saved to %s', model_filename)\n",
        "print('Done!')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all triples :  [(0, 4, 4, 0.79839295), (1, 1, 1, 0.7983928), (2, 4, 4, 0.79839295), (3, 5, 5, 0.7980337), (4, 9, 4, 0.6371158), (5, 9, 4, 0.6371139), (6, 4, 4, 0.79839295), (7, 9, 4, 0.6371139), (8, 1, 1, 0.7983928), (9, 5, 5, 0.7980337), (10, 9, 4, 0.6371158), (11, 1, 1, 0.7983921), (12, 9, 4, 0.6371158), (13, 9, 4, 0.52998406), (14, 9, 4, 0.5299846), (15, 9, 4, 0.6371139), (16, 7, 7, 0.79839295), (17, 5, 5, 0.7980337), (18, 4, 4, 0.79839295), (19, 9, 4, 0.6371139), (20, 5, 5, 0.7980337), (21, 9, 4, 0.6371139), (22, 9, 4, 0.6371158), (23, 9, 4, 0.6371139), (24, 0, 0, 0.79839224), (25, 4, 4, 0.79839295), (26, 9, 4, 0.6371158), (27, 4, 4, 0.79839295), (28, 4, 4, 0.79839295), (29, 9, 4, 0.6371139), (30, 9, 4, 0.6371158), (31, 4, 4, 0.79839295), (32, 4, 4, 0.79839295), (33, 4, 4, 0.79839295), (34, 1, 1, 0.7983928), (35, 9, 4, 0.6371139), (36, 9, 4, 0.6371158), (37, 9, 4, 0.6371139), (38, 9, 4, 0.6371158), (39, 9, 4, 0.6371139), (40, 1, 1, 0.7983928), (41, 9, 4, 0.6371139), (42, 9, 4, 0.6371158), (43, 4, 4, 0.79839295), (44, 4, 4, 0.79839295), (45, 9, 4, 0.6371139), (46, 9, 4, 0.6371158), (47, 9, 4, 0.6371139), (48, 4, 4, 0.79839295), (49, 9, 4, 0.6371139), (50, 9, 4, 0.6371158), (51, 0, 0, 0.79839224), (52, 2, 2, 0.7983929), (53, 4, 4, 0.79839295), (54, 9, 4, 0.6371158), (55, 0, 0, 0.79839224), (56, 9, 4, 0.5299846), (57, 9, 4, 0.6371139), (58, 4, 4, 0.79839295), (59, 4, 4, 0.79839295), (60, 5, 5, 0.7980337), (61, 9, 4, 0.6371139), (62, 4, 4, 0.79839295), (63, 2, 2, 0.7983929), (64, 9, 4, 0.6371158), (65, 5, 5, 0.7980337), (66, 7, 7, 0.79839295), (67, 9, 4, 0.6371139), (68, 0, 0, 0.79839224), (69, 9, 4, 0.6371139), (70, 2, 2, 0.7983929), (71, 9, 4, 0.6371139), (72, 9, 4, 0.6371158), (73, 7, 7, 0.79839295), (74, 9, 4, 0.6371158), (75, 5, 5, 0.7980337), (76, 1, 1, 0.7983928), (77, 9, 4, 0.6371139), (78, 7, 7, 0.79839295), (79, 1, 1, 0.7983921), (80, 9, 4, 0.6371158), (81, 7, 7, 0.79839295), (82, 1, 1, 0.7983928), (83, 9, 4, 0.6371139), (84, 9, 4, 0.6371158), (85, 4, 4, 0.79839295), (86, 1, 1, 0.7983921), (87, 2, 2, 0.7983929), (88, 9, 4, 0.6371158), (89, 9, 4, 0.52998406), (90, 9, 4, 0.6371158), (91, 0, 0, 0.79839224), (92, 4, 4, 0.79839295), (93, 2, 2, 0.7983929), (94, 9, 4, 0.6371158), (95, 7, 7, 0.79839295), (96, 1, 1, 0.7983928), (97, 9, 4, 0.6371139), (98, 4, 4, 0.79839295), (99, 0, 0, 0.79839224), (100, 4, 4, 0.79839295), (101, 1, 1, 0.7983921), (102, 7, 7, 0.79839295), (103, 9, 4, 0.6371139), (104, 1, 1, 0.7983928), (105, 4, 4, 0.79839295), (106, 5, 5, 0.7980337), (107, 9, 4, 0.6371139), (108, 9, 4, 0.5299846), (109, 9, 4, 0.52998406), (110, 4, 4, 0.79839295), (111, 9, 4, 0.52998406), (112, 9, 4, 0.5299846), (113, 4, 4, 0.79839295), (114, 1, 1, 0.7983921), (115, 1, 1, 0.7983928), (116, 2, 2, 0.7983929), (117, 9, 4, 0.52998406), (118, 9, 4, 0.6371158), (119, 1, 1, 0.7983921), (120, 9, 4, 0.6371158), (121, 9, 4, 0.6371139), (122, 5, 5, 0.7980337), (123, 9, 4, 0.6371139), (124, 9, 4, 0.5299846), (125, 9, 4, 0.6371139), (126, 1, 1, 0.7983928), (127, 4, 4, 0.79839295), (128, 9, 4, 0.5299846), (129, 9, 4, 0.6371139), (130, 9, 4, 0.6371158), (131, 9, 4, 0.52998406), (132, 9, 4, 0.6371158), (133, 2, 2, 0.7983929), (134, 7, 7, 0.79839295), (135, 9, 4, 0.6371139), (136, 9, 4, 0.6371158), (137, 5, 5, 0.7980337), (138, 1, 1, 0.7983928), (139, 9, 4, 0.6371139), (140, 2, 2, 0.7983929), (141, 9, 4, 0.6371139), (142, 9, 4, 0.6371158), (143, 9, 4, 0.52998406), (144, 9, 4, 0.5299846), (145, 7, 7, 0.79839295), (146, 7, 7, 0.79839295), (147, 4, 4, 0.79839295), (148, 5, 5, 0.7980337), (149, 5, 5, 0.7980337), (150, 2, 2, 0.7983929), (151, 1, 1, 0.7983928), (152, 2, 2, 0.7983929), (153, 1, 1, 0.7983921), (154, 1, 1, 0.7983921), (155, 1, 1, 0.7983921), (156, 4, 4, 0.79839295), (157, 9, 4, 0.6371139), (158, 1, 1, 0.7983928), (159, 1, 1, 0.7983928), (160, 7, 7, 0.79839295), (161, 9, 4, 0.6371139), (162, 9, 4, 0.6371158), (163, 1, 1, 0.7983921), (164, 9, 4, 0.6371158), (165, 9, 4, 0.6371139), (166, 0, 0, 0.79839224), (167, 5, 5, 0.7980337), (168, 5, 5, 0.7980337), (169, 9, 4, 0.6371139), (170, 9, 4, 0.6371158), (171, 9, 4, 0.52998406), (172, 9, 4, 0.6371158), (173, 9, 4, 0.52998406), (174, 9, 4, 0.6371158), (175, 9, 4, 0.6371139), (176, 9, 4, 0.6371158), (177, 9, 4, 0.6371139), (178, 9, 4, 0.6371158), (179, 9, 4, 0.6371139), (180, 7, 7, 0.79839295), (181, 4, 4, 0.79839295), (182, 9, 4, 0.6371158), (183, 1, 1, 0.7983928), (184, 9, 4, 0.6371158), (185, 9, 4, 0.6371139), (186, 9, 4, 0.6371158), (187, 9, 4, 0.6371139), (188, 5, 5, 0.7980337), (189, 9, 4, 0.6371139), (190, 4, 4, 0.79839295), (191, 2, 2, 0.7983929), (192, 9, 4, 0.6371158), (193, 2, 2, 0.7983929), (194, 1, 1, 0.7983928), (195, 2, 2, 0.7983929), (196, 9, 4, 0.6371158), (197, 2, 2, 0.7983929), (198, 9, 4, 0.6371158), (199, 0, 0, 0.79839224), (200, 4, 4, 0.79839295), (201, 2, 2, 0.7983929), (202, 9, 4, 0.5299846), (203, 4, 4, 0.79839295), (204, 9, 4, 0.6371158), (205, 9, 4, 0.6371139), (206, 9, 4, 0.6371158), (207, 9, 4, 0.52998406), (208, 4, 4, 0.79839295), (209, 9, 4, 0.6371139), (210, 9, 4, 0.6371158), (211, 9, 4, 0.6371139), (212, 1, 1, 0.7983928), (213, 9, 4, 0.6371139), (214, 1, 1, 0.7983921), (215, 0, 0, 0.79839224), (216, 2, 2, 0.7983929), (217, 9, 4, 0.52998406), (218, 9, 4, 0.6371158), (219, 9, 4, 0.6371139), (220, 5, 5, 0.7980337), (221, 9, 4, 0.6371139), (222, 4, 4, 0.79839295), (223, 4, 4, 0.79839295), (224, 9, 4, 0.6371158), (225, 9, 4, 0.6371139), (226, 9, 4, 0.6371158), (227, 9, 4, 0.6371139), (228, 9, 4, 0.6371158), (229, 9, 4, 0.6371139), (230, 9, 4, 0.6371158), (231, 9, 4, 0.6371139), (232, 4, 4, 0.79839295), (233, 5, 5, 0.7980337), (234, 7, 7, 0.79839295), (235, 7, 7, 0.79839295), (236, 1, 1, 0.7983928), (237, 1, 1, 0.7983928), (238, 9, 4, 0.6371158), (239, 1, 1, 0.7983921), (240, 7, 7, 0.79839295), (241, 9, 4, 0.6371139), (242, 9, 4, 0.6371158), (243, 4, 4, 0.79839295), (244, 7, 7, 0.79839295), (245, 9, 4, 0.6371139), (246, 4, 4, 0.79839295), (247, 9, 4, 0.52998406), (248, 9, 4, 0.5299846), (249, 0, 0, 0.79839224), (250, 9, 4, 0.6371158), (251, 9, 4, 0.6371139), (252, 5, 5, 0.7980337), (253, 1, 1, 0.7983928), (254, 7, 7, 0.79839295), (255, 4, 4, 0.79839295)]\n",
            "anomaly triples:  [(4, 9, 4, 0.6371158), (5, 9, 4, 0.6371139), (7, 9, 4, 0.6371139), (10, 9, 4, 0.6371158), (12, 9, 4, 0.6371158), (13, 9, 4, 0.52998406), (14, 9, 4, 0.5299846), (15, 9, 4, 0.6371139), (19, 9, 4, 0.6371139), (21, 9, 4, 0.6371139), (22, 9, 4, 0.6371158), (23, 9, 4, 0.6371139), (26, 9, 4, 0.6371158), (29, 9, 4, 0.6371139), (30, 9, 4, 0.6371158), (35, 9, 4, 0.6371139), (36, 9, 4, 0.6371158), (37, 9, 4, 0.6371139), (38, 9, 4, 0.6371158), (39, 9, 4, 0.6371139), (41, 9, 4, 0.6371139), (42, 9, 4, 0.6371158), (45, 9, 4, 0.6371139), (46, 9, 4, 0.6371158), (47, 9, 4, 0.6371139), (49, 9, 4, 0.6371139), (50, 9, 4, 0.6371158), (54, 9, 4, 0.6371158), (56, 9, 4, 0.5299846), (57, 9, 4, 0.6371139), (61, 9, 4, 0.6371139), (64, 9, 4, 0.6371158), (67, 9, 4, 0.6371139), (69, 9, 4, 0.6371139), (71, 9, 4, 0.6371139), (72, 9, 4, 0.6371158), (74, 9, 4, 0.6371158), (77, 9, 4, 0.6371139), (80, 9, 4, 0.6371158), (83, 9, 4, 0.6371139), (84, 9, 4, 0.6371158), (88, 9, 4, 0.6371158), (89, 9, 4, 0.52998406), (90, 9, 4, 0.6371158), (94, 9, 4, 0.6371158), (97, 9, 4, 0.6371139), (103, 9, 4, 0.6371139), (107, 9, 4, 0.6371139), (108, 9, 4, 0.5299846), (109, 9, 4, 0.52998406), (111, 9, 4, 0.52998406), (112, 9, 4, 0.5299846), (117, 9, 4, 0.52998406), (118, 9, 4, 0.6371158), (120, 9, 4, 0.6371158), (121, 9, 4, 0.6371139), (123, 9, 4, 0.6371139), (124, 9, 4, 0.5299846), (125, 9, 4, 0.6371139), (128, 9, 4, 0.5299846), (129, 9, 4, 0.6371139), (130, 9, 4, 0.6371158), (131, 9, 4, 0.52998406), (132, 9, 4, 0.6371158), (135, 9, 4, 0.6371139), (136, 9, 4, 0.6371158), (139, 9, 4, 0.6371139), (141, 9, 4, 0.6371139), (142, 9, 4, 0.6371158), (143, 9, 4, 0.52998406), (144, 9, 4, 0.5299846), (157, 9, 4, 0.6371139), (161, 9, 4, 0.6371139), (162, 9, 4, 0.6371158), (164, 9, 4, 0.6371158), (165, 9, 4, 0.6371139), (169, 9, 4, 0.6371139), (170, 9, 4, 0.6371158), (171, 9, 4, 0.52998406), (172, 9, 4, 0.6371158), (173, 9, 4, 0.52998406), (174, 9, 4, 0.6371158), (175, 9, 4, 0.6371139), (176, 9, 4, 0.6371158), (177, 9, 4, 0.6371139), (178, 9, 4, 0.6371158), (179, 9, 4, 0.6371139), (182, 9, 4, 0.6371158), (184, 9, 4, 0.6371158), (185, 9, 4, 0.6371139), (186, 9, 4, 0.6371158), (187, 9, 4, 0.6371139), (189, 9, 4, 0.6371139), (192, 9, 4, 0.6371158), (196, 9, 4, 0.6371158), (198, 9, 4, 0.6371158), (202, 9, 4, 0.5299846), (204, 9, 4, 0.6371158), (205, 9, 4, 0.6371139), (206, 9, 4, 0.6371158), (207, 9, 4, 0.52998406), (209, 9, 4, 0.6371139), (210, 9, 4, 0.6371158), (211, 9, 4, 0.6371139), (213, 9, 4, 0.6371139), (217, 9, 4, 0.52998406), (218, 9, 4, 0.6371158), (219, 9, 4, 0.6371139), (221, 9, 4, 0.6371139), (224, 9, 4, 0.6371158), (225, 9, 4, 0.6371139), (226, 9, 4, 0.6371158), (227, 9, 4, 0.6371139), (228, 9, 4, 0.6371158), (229, 9, 4, 0.6371139), (230, 9, 4, 0.6371158), (231, 9, 4, 0.6371139), (238, 9, 4, 0.6371158), (241, 9, 4, 0.6371139), (242, 9, 4, 0.6371158), (245, 9, 4, 0.6371139), (247, 9, 4, 0.52998406), (248, 9, 4, 0.5299846), (250, 9, 4, 0.6371158), (251, 9, 4, 0.6371139)]\n",
            "modified anomaly triples: [(4, 9, 9, 0.6371158), (5, 9, 9, 0.6371139), (7, 9, 9, 0.6371139), (10, 9, 9, 0.6371158), (12, 9, 9, 0.6371158), (13, 9, 9, 0.52998406), (14, 9, 9, 0.5299846), (15, 9, 9, 0.6371139), (19, 9, 9, 0.6371139), (21, 9, 9, 0.6371139), (22, 9, 9, 0.6371158), (23, 9, 9, 0.6371139), (26, 9, 9, 0.6371158), (29, 9, 9, 0.6371139), (30, 9, 9, 0.6371158), (35, 9, 9, 0.6371139), (36, 9, 9, 0.6371158), (37, 9, 9, 0.6371139), (38, 9, 9, 0.6371158), (39, 9, 9, 0.6371139), (41, 9, 9, 0.6371139), (42, 9, 9, 0.6371158), (45, 9, 9, 0.6371139), (46, 9, 9, 0.6371158), (47, 9, 9, 0.6371139), (49, 9, 9, 0.6371139), (50, 9, 9, 0.6371158), (54, 9, 9, 0.6371158), (56, 9, 9, 0.5299846), (57, 9, 9, 0.6371139), (61, 9, 9, 0.6371139), (64, 9, 9, 0.6371158), (67, 9, 9, 0.6371139), (69, 9, 9, 0.6371139), (71, 9, 9, 0.6371139), (72, 9, 9, 0.6371158), (74, 9, 9, 0.6371158), (77, 9, 9, 0.6371139), (80, 9, 9, 0.6371158), (83, 9, 9, 0.6371139), (84, 9, 9, 0.6371158), (88, 9, 9, 0.6371158), (89, 9, 9, 0.52998406), (90, 9, 9, 0.6371158), (94, 9, 9, 0.6371158), (97, 9, 9, 0.6371139), (103, 9, 9, 0.6371139), (107, 9, 9, 0.6371139), (108, 9, 9, 0.5299846), (109, 9, 9, 0.52998406), (111, 9, 9, 0.52998406), (112, 9, 9, 0.5299846), (117, 9, 9, 0.52998406), (118, 9, 9, 0.6371158), (120, 9, 9, 0.6371158), (121, 9, 9, 0.6371139), (123, 9, 9, 0.6371139), (124, 9, 9, 0.5299846), (125, 9, 9, 0.6371139), (128, 9, 9, 0.5299846), (129, 9, 9, 0.6371139), (130, 9, 9, 0.6371158), (131, 9, 9, 0.52998406), (132, 9, 9, 0.6371158), (135, 9, 9, 0.6371139), (136, 9, 9, 0.6371158), (139, 9, 9, 0.6371139), (141, 9, 9, 0.6371139), (142, 9, 9, 0.6371158), (143, 9, 9, 0.52998406), (144, 9, 9, 0.5299846), (157, 9, 9, 0.6371139), (161, 9, 9, 0.6371139), (162, 9, 9, 0.6371158), (164, 9, 9, 0.6371158), (165, 9, 9, 0.6371139), (169, 9, 9, 0.6371139), (170, 9, 9, 0.6371158), (171, 9, 9, 0.52998406), (172, 9, 9, 0.6371158), (173, 9, 9, 0.52998406), (174, 9, 9, 0.6371158), (175, 9, 9, 0.6371139), (176, 9, 9, 0.6371158), (177, 9, 9, 0.6371139), (178, 9, 9, 0.6371158), (179, 9, 9, 0.6371139), (182, 9, 9, 0.6371158), (184, 9, 9, 0.6371158), (185, 9, 9, 0.6371139), (186, 9, 9, 0.6371158), (187, 9, 9, 0.6371139), (189, 9, 9, 0.6371139), (192, 9, 9, 0.6371158), (196, 9, 9, 0.6371158), (198, 9, 9, 0.6371158), (202, 9, 9, 0.5299846), (204, 9, 9, 0.6371158), (205, 9, 9, 0.6371139), (206, 9, 9, 0.6371158), (207, 9, 9, 0.52998406), (209, 9, 9, 0.6371139), (210, 9, 9, 0.6371158), (211, 9, 9, 0.6371139), (213, 9, 9, 0.6371139), (217, 9, 9, 0.52998406), (218, 9, 9, 0.6371158), (219, 9, 9, 0.6371139), (221, 9, 9, 0.6371139), (224, 9, 9, 0.6371158), (225, 9, 9, 0.6371139), (226, 9, 9, 0.6371158), (227, 9, 9, 0.6371139), (228, 9, 9, 0.6371158), (229, 9, 9, 0.6371139), (230, 9, 9, 0.6371158), (231, 9, 9, 0.6371139), (238, 9, 9, 0.6371158), (241, 9, 9, 0.6371139), (242, 9, 9, 0.6371158), (245, 9, 9, 0.6371139), (247, 9, 9, 0.52998406), (248, 9, 9, 0.5299846), (250, 9, 9, 0.6371158), (251, 9, 9, 0.6371139)]\n",
            "[[ 10   0   0   0   0   0   0]\n",
            " [  0  32   0   0   0   0   0]\n",
            " [  0   0  16   0   0   0   0]\n",
            " [  0   0   0  38   0   0   0]\n",
            " [  0   0   0   0  18   0   0]\n",
            " [  0   0   0   0   0  17   0]\n",
            " [  0   0   0   0   0   0 125]]\n",
            "Precision: %d 1.0\n",
            "Recall: %d 1.0\n",
            "F1 Score: %d 1.0\n",
            "Optimal temperature: 0.280\n",
            "After temperature - NLL: 1.714, ECE: 0.405\n",
            "Anomaly Count: 125\n",
            "[1 4 9 9 9 2 9 9 1 9 1 9 4 4 9 4 1 9 1 9 9 5 1 9 0 9 9 0 9 0 4 4 5 4 5 5 1\n",
            " 1 9 4 5 9 4 7 9 9 2 1 4 9 0 9 7 9 4 1 9 9 2 7 1 7 9 4 1 9 4 9 9 0 0 0 1 9\n",
            " 4 2 9 9 1 2 9 9 9 4 1 9 9 9 9 9 5 1 9 4 2 1 4 4 1 1 9 9 1 7 9 4 4 9 9 0 9\n",
            " 1 9 9 4 9 9 9 9 2 4 0 4 9 9 9 1 2 1 1 7 9 5 9 4 9 1 0 4 2 5 9 9 9 5 4 7 5\n",
            " 9 9 9 9 4 5 9 9 1 5 5 9 9 9 9 4 9 9 4 4 7 4 9 9 4 9 0 5 9 4 9 9 9 1 9 4 9\n",
            " 9 1 9 9 2 4 4 1 9 0 0 9 2 1 9 0 1 9 9 9 9 0 0 4 4 2 9 9 9 9 9 7 9 9 2 9 4\n",
            " 0 1 9 9 4 7 9 1 2 9 9 4 1 4 2 7 4 9 9 1 9 9 1 1 9 4 9 7 4 9 7 1 5 9]\n",
            "[tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0001), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0001), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0001), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0001), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0001), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0001), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0001), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0001), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0001), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0001), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0001), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0001), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.0000), tensor(1.), tensor(1.), tensor(1.), tensor(1.0000)]\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Temperature scaled model saved to %s model_with_temperature.pth\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wPwAyxghVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}